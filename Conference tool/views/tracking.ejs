<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>EdEmo Detector</title>
  <script src="js/face-api.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.1.0/chart.min.js"></script>
  <script src='https://cdn.plot.ly/plotly-latest.min.js'></script>
  <link rel="stylesheet" href="css/tracking.css">
  <link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"
/>
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Rajdhani&display=swap" rel="stylesheet">
  <!-- <script defer src="script.js"></script> -->
  <style>
    body {
     background-color: #1a1f3f;
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display:flex;
      font-family: 'Rajdhani',sans-serif;
    }

    canvas {
      position: absolute;
      margin-top: 10%;
      margin-left: 5%;
    }
  </style>
</head>
<body>
    <h1>Tracking on Progress</h1>
  <video id="video" width="650" height="560" autoplay muted></video>
  <!-- <div id="chart_container"> -->
<div id="bar-chart-container"></div>
  </div>

  <button id="start"><i class="fa fa-play" aria-hidden="true"></i></button>
  <button id="stop" onclick="plotBarGraph()"><i class="fa fa-stop" aria-hidden="true"></i></button>
  <button id="share" onclick="openForm()" ><i class="fa fa-share" aria-hidden="true"></i></button>


  <form id="form">
      <input type="text" placeholder="Enter name"class="input" required>
      <input type="email" name="mailto" placeholder="Mail to" class="input" required>
      <input type="datetime-local" name="datetime" class="input" required>
      <input type="file" name="imgupload" class="choose" required>
      <br>
      <input type="submit" value="Send" id="sendBtn">
      <input type="button" value="Close" id="closeBtn" onclick="closeForm()">
  </form>


  <div id="face"></div>
  <div id="final_chart"></div>
  <script>
      const video = document.getElementById('video')

      var el = document.getElementById('stop');
      var clicked=false;
      var clickHandler = function () {
        clicked=!clicked
        if (clicked){
            console.log("button clicked")
        }else{
            console.log("button not clicked");
        }
      }

        Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('js/models'),
        faceapi.nets.faceLandmark68Net.loadFromUri('js/models'),
        faceapi.nets.faceRecognitionNet.loadFromUri('js/models'),
        faceapi.nets.faceExpressionNet.loadFromUri('js/models')
        ]).then(startVideo)

        function startVideo() {
        navigator.getUserMedia(
            { video: {} },
            stream => video.srcObject = stream,
            err => console.error(err)
        )
        }



        const face = document.getElementById('face');
        let statusIcons = {
          default: 'ðŸ˜Ž',
          neutral: 'ðŸ™‚',
          happy: 'ðŸ˜€',
          sad: 'ðŸ˜¥',
          angry: 'ðŸ˜ ',
          fearful: 'ðŸ˜¨',
          disgusted: 'ðŸ¤¢',
          surprised: 'ðŸ¤¯'
        }

        function detectExpression() {
          // 005 - Set the default Emoji
          face.innerHTML = statusIcons.default
            const canvas = faceapi.createCanvasFromMedia(video)
          // 006 - setInterval to detect face/espression periodically (every 500 milliseconds)
          const milliseconds = 500
          setInterval(async () => {
            // 007 - Wait to detect face with Expression
            document.body.append(canvas)
            const displaySize = { width: video.width, height: video.height }
            faceapi.matchDimensions(canvas, displaySize)
            const detection = await  faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()
            console.log(detection)
            const resizedDetections = faceapi.resizeResults(detection, displaySize)
            let chart = canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
            faceapi.draw.drawDetections(canvas, resizedDetections)
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
            faceapi.draw.drawFaceExpressions(canvas, resizedDetections)    
           
            let barChartData = {
                default: 0,
                neutral: 0,
                happy: 0,
                sad: 0,
                angry: 0,
                fearful: 0,
                disgusted: 0,
                surprised: 0
              }
            // 008 - detectAllFaces retruns an array of faces with some interesting attributes
            if (detection.length > 0) {
              // 009 - walk through all faces detected
              detection.forEach(element => {
                /**
                 * 010 - each face element has a expressions attribute
                 * for example:
                 * neutral: 0.33032259345054626
                 * happy: 0.0004914478631690145
                 * sad: 0.6230283975601196
                 * angry: 0.042668383568525314
                 * fearful: 0.000010881130037887488
                 * disgusted: 0.003466457361355424
                 * surprised: 0.000011861078746733256
                 */
                let status = "";
                let valueStatus = 0.0;
                for (const [key, value] of Object.entries(element.expressions)) {
                  if (value > valueStatus) {
                    status = key
                    valueStatus = value;
                    // console.log(status)


                    
                    var time = new Date();

                    var data = [{
                      x: [time],
                      // y: ["Happy","Neutral","Surprised","Sad","Fearful","Disgutsed","Angry"],
                      y:[status],
                      mode: 'line',
                      line: {color: '#80CAF6'}
                    }]


                    // Plotly.newPlot('chart_container', data);

                    if (!clicked){
                      barChartData[status]++;
                      console.log("Collecting data to bar graph..");
                    }

                    var cnt = 0;
                    var interval = setInterval(function () {

                      var time = new Date();

                      var update = {
                      x:  [[time]],
                      // y: [["Happy","Neutral","Surprised","Sad","Fearful","Disgutsed","Angry"]]
                      y:[[status]]
                      }

                      // Plotly.extendTraces('chart_container', update, [0])

                      if(++cnt === 100) clearInterval(interval);
                    }, 1000);


                                    
                      // var timeoutId,
                      //   startButton = document.getElementById('start'),
                      //   stopButton = document.getElementById('stop');

                      // function startDetection() {
                      //   timeoutId = setInterval(function(){updateChart()}, updateInterval);
                      //   startButton.removeEventListener('click', startDetection);
                      //   stopButton.addEventListener('click', stopDetection);
                      // }

                      // function stopDetection() {
                      //   clearTimeout(timeoutId);
                      //   stopButton.removeEventListener('click', stopDetection);
                      //   startButton.addEventListener('click', startDetection);
                      //     Plotly.downloadImage('chart_container', {format: 'png', width: 800, height: 600, filename: 'newplot'});
                      // }  


                    }
                }
                // 011 - once we have the highest scored expression (status) we display the right Emoji
                face.innerHTML = statusIcons[status]
              });
            } else {
              console.log("No Faces")
              //face.innerHTML = statusIcons.default;
            }
          }, milliseconds);
        }

        // 012 - Add a listener once the Video is played
        video.addEventListener('playing', () => {
          detectExpression()
          


        })         


        
        document.getElementById('form').style.display="none";

        function openForm(){
            document.getElementById('form').style.display="block";
            document.getElementById('share').style.display="none";
        }
        function closeForm(){
            document.getElementById('form').style.display="none";
            document.getElementById('share').style.display="block";
        }
      
        function plotBarGraph(){
          var data = [
          {
            x: Object.keys(barChartData),
            y: Object.values(barChartData),
            type: 'bar'
          }
          ];

          Plotly.newPlot('bar-chart-container', data);
        }
    

  </script>
</body>
</html>